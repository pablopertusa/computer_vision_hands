{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pruebas Trabajo con MLPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-05 13:40:34.493407: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1733402434.511731   43208 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1733402434.517124   43208 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-12-05 13:40:34.537222: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from keras.optimizers import SGD\n",
    "from tensorflow import keras\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from keras import Sequential\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from keras.layers import Dense, Input, Dropout, Flatten\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report, roc_auc_score, roc_curve\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_results_gs(gs, sort=False):\n",
    "    # Extraer los resultados del GridSearchCV\n",
    "    results = gs.cv_results_\n",
    "\n",
    "    # Crear un DataFrame con los parámetros y los resultados medios\n",
    "    df_results = pd.DataFrame({\n",
    "        'mean_test_score': results['mean_test_score'],\n",
    "        'params': results['params']\n",
    "    })\n",
    "\n",
    "    # Ordenar los resultados por el resultado promedio (opcional)\n",
    "    if sort:\n",
    "        df_results = df_results.sort_values(by='mean_test_score', ascending=False)\n",
    "\n",
    "    # Mostrar los resultados\n",
    "    print(df_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "Comprobación: True\n"
     ]
    }
   ],
   "source": [
    "dataset_path = '/home/pablo/Desktop/tercero/mdp/trabajo/HANDS'   # Cambiar por la carpeta en la que se encuentran las imágenes\n",
    " \n",
    "jpgFiles = [fJPG for fJPG in os.listdir(dataset_path) if fJPG.endswith('.jpg')]\n",
    "\n",
    "bufferImages = []\n",
    "y = []\n",
    "\n",
    "# Extraer 50 patches aleatorios de cada imagen\n",
    "for filename in jpgFiles:\n",
    "    img_path = os.path.join(dataset_path, filename)\n",
    "    label = filename.split('.')[0][-2:]\n",
    "    y.append(label)\n",
    "    with open(img_path) as infile:\n",
    "        # Obtener etiqueta\n",
    "        img_label = filename[5:7] \n",
    "        # Leer imagen\n",
    "        img = cv2.imread(img_path)\n",
    "        # Convertir imagen de BGR a RGB\n",
    "        img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        bufferImages.append(img_gray)\n",
    "print(len(bufferImages))\n",
    "print('Comprobación:', all([x in ['RB', 'RF', 'LB', 'LF'] for x in y]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomPreprocessorSamePatches(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, patchSize=10, nClusters = 81, max_patches=50):\n",
    "        self.patchSize = patchSize\n",
    "        self.nClusters = nClusters\n",
    "        self.max_patches = max_patches\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self       \n",
    "    \n",
    "    def extract_centric_patches(self, img, patch_size, num_patches, seed=42):\n",
    "        assert img.shape[0] == 150 and img.shape[1] == 150, \"La imagen debe tener resolución 150x150.\"\n",
    "        assert patch_size > 0, \"El tamaño del patch debe ser mayor que 0.\"\n",
    "        assert patch_size * num_patches <= 150 * 150, \"Demasiados patches para esta resolución.\"\n",
    "        \n",
    "        # Calcular la cuadrícula de celdas no superpuestas\n",
    "        grid_rows = 150 // patch_size\n",
    "        grid_cols = 150 // patch_size\n",
    "        total_cells = grid_rows * grid_cols\n",
    "\n",
    "        assert num_patches <= total_cells, \"Demasiados patches para el tamaño del patch y la resolución de la imagen.\"\n",
    "        \n",
    "        # Generar las posiciones de la cuadrícula\n",
    "        all_positions = [(i * patch_size, j * patch_size) for i in range(grid_rows) for j in range(grid_cols)]\n",
    "\n",
    "        # Calcular las distancias de las celdas al centro de la imagen\n",
    "        center = (150 // 2, 150 // 2)\n",
    "        distances = [\n",
    "            np.sqrt((row + patch_size // 2 - center[0])**2 + (col + patch_size // 2 - center[1])**2)\n",
    "            for row, col in all_positions\n",
    "        ]\n",
    "\n",
    "        # Ordenar las posiciones por cercanía al centro\n",
    "        sorted_positions = [pos for _, pos in sorted(zip(distances, all_positions))]\n",
    "        \n",
    "        # Seleccionar los patches más céntricos\n",
    "        np.random.seed(seed)\n",
    "        selected_positions = sorted_positions[:num_patches]\n",
    "        \n",
    "        # Extraer los patches en las posiciones seleccionadas\n",
    "        patches = [img[row:row + patch_size, col:col + patch_size] for row, col in selected_positions]\n",
    "\n",
    "        #self.visualize_disjoint_patches(img, patches, selected_positions, patch_size)\n",
    "        \n",
    "        return np.array(patches)\n",
    "\n",
    "\n",
    "    def bovw(self, images, patchSize, nClusters, maxPatches):\n",
    "        bufferData = []\n",
    "        for i in images:\n",
    "            resized_img = cv2.resize(i, (150, 150), interpolation=cv2.INTER_AREA)\n",
    "            patches = self.extract_centric_patches(resized_img, patchSize, num_patches=maxPatches, seed=27)\n",
    "            patches = np.reshape(patches, (len(patches), -1))\n",
    "            bufferData.append(patches)\n",
    "            \n",
    "        bufferData = np.array(bufferData)\n",
    "        print(bufferData.shape)\n",
    "        return bufferData\n",
    "\n",
    "    def transform(self, images):\n",
    "        # Aplica tu función de preprocesamiento aquí\n",
    "        # Por ejemplo:\n",
    "        # return your_custom_function(X, param1=self.param1)\n",
    "        return self.bovw(images, self.patchSize, self.nClusters, self.max_patches)  # Devuelve los datos preprocesados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1733402437.533376   43208 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5787 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Input(shape=(50, 300)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(4, activation='softmax'))\n",
    "model.compile(optimizer = SGD(), loss='categorical_crossentropy',\n",
    "                metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 50, 300)\n"
     ]
    }
   ],
   "source": [
    "cp = CustomPreprocessorSamePatches()\n",
    "resul = cp.transform(bufferImages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1733402438.835599   43524 service.cc:148] XLA service 0x78e14c003580 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1733402438.835625   43524 service.cc:156]   StreamExecutor device (0): NVIDIA GeForce RTX 4060 Laptop GPU, Compute Capability 8.9\n",
      "2024-12-05 13:40:38.852517: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1733402438.898968   43524 cuda_dnn.cc:529] Loaded cuDNN version 90300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.2546 - loss: nan        \n",
      "Epoch 2/60\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2400 - loss: nan\n",
      "Epoch 3/60\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3008 - loss: nan\n",
      "Epoch 4/60\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2579 - loss: nan\n",
      "Epoch 5/60\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2302 - loss: nan\n",
      "Epoch 6/60\n",
      "\u001b[1m 2/10\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2344 - loss: nan "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1733402441.061391   43524 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2674 - loss: nan\n",
      "Epoch 7/60\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2676 - loss: nan\n",
      "Epoch 8/60\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2464 - loss: nan\n",
      "Epoch 9/60\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2268 - loss: nan\n",
      "Epoch 10/60\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2487 - loss: nan\n",
      "Epoch 11/60\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2848 - loss: nan\n",
      "Epoch 12/60\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2983 - loss: nan\n",
      "Epoch 13/60\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2742 - loss: nan\n",
      "Epoch 14/60\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2445 - loss: nan\n",
      "Epoch 15/60\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2874 - loss: nan\n",
      "Epoch 16/60\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2436 - loss: nan\n",
      "Epoch 17/60\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2280 - loss: nan\n",
      "Epoch 18/60\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2365 - loss: nan\n",
      "Epoch 19/60\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2655 - loss: nan\n",
      "Epoch 20/60\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2316 - loss: nan\n",
      "Epoch 21/60\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2365 - loss: nan\n",
      "Epoch 22/60\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2321 - loss: nan\n",
      "Epoch 23/60\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2696 - loss: nan\n",
      "Epoch 24/60\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3057 - loss: nan\n",
      "Epoch 25/60\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3188 - loss: nan\n",
      "Epoch 26/60\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2679 - loss: nan\n",
      "Epoch 27/60\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2435 - loss: nan\n",
      "Epoch 28/60\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2403 - loss: nan\n",
      "Epoch 29/60\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2599 - loss: nan\n",
      "Epoch 30/60\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2146 - loss: nan\n",
      "Epoch 31/60\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2788 - loss: nan\n",
      "Epoch 32/60\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2328 - loss: nan\n",
      "Epoch 33/60\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2580 - loss: nan\n",
      "Epoch 34/60\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2719 - loss: nan\n",
      "Epoch 35/60\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2796 - loss: nan\n",
      "Epoch 36/60\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2528 - loss: nan\n",
      "Epoch 37/60\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2705 - loss: nan\n",
      "Epoch 38/60\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2421 - loss: nan\n",
      "Epoch 39/60\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2412 - loss: nan\n",
      "Epoch 40/60\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2811 - loss: nan\n",
      "Epoch 41/60\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3320 - loss: nan\n",
      "Epoch 42/60\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2634 - loss: nan\n",
      "Epoch 43/60\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2540 - loss: nan\n",
      "Epoch 44/60\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2738 - loss: nan\n",
      "Epoch 45/60\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2498 - loss: nan\n",
      "Epoch 46/60\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2747 - loss: nan\n",
      "Epoch 47/60\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2844 - loss: nan\n",
      "Epoch 48/60\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2515 - loss: nan\n",
      "Epoch 49/60\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2680 - loss: nan\n",
      "Epoch 50/60\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2540 - loss: nan\n",
      "Epoch 51/60\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2689 - loss: nan\n",
      "Epoch 52/60\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2495 - loss: nan\n",
      "Epoch 53/60\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2319 - loss: nan\n",
      "Epoch 54/60\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3402 - loss: nan\n",
      "Epoch 55/60\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2410 - loss: nan\n",
      "Epoch 56/60\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2736 - loss: nan\n",
      "Epoch 57/60\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2682 - loss: nan\n",
      "Epoch 58/60\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2458 - loss: nan\n",
      "Epoch 59/60\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2613 - loss: nan\n",
      "Epoch 60/60\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2854 - loss: nan\n"
     ]
    }
   ],
   "source": [
    "enc = LabelEncoder()\n",
    "y_cat = enc.fit_transform(y)\n",
    "y_one_hot = to_categorical(y_cat, 4)\n",
    "x_train, x_test, y_train, y_test = train_test_split(resul, y_one_hot, test_size=0.2)\n",
    "\n",
    "history = model.fit(x_train, y_train, epochs=60, batch_size=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Desastre"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pruebas con BoVW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomBoVWPreprocessorSamePatches(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, patchSize=10, nClusters = 81, max_patches=50):\n",
    "        self.patchSize = patchSize\n",
    "        self.nClusters = nClusters\n",
    "        self.max_patches = max_patches\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self     \n",
    "    \n",
    "    def extract_centric_patches(self, img, patch_size, num_patches, seed=42):\n",
    "        assert img.shape[0] == 150 and img.shape[1] == 150, \"La imagen debe tener resolución 150x150.\"\n",
    "        assert patch_size > 0, \"El tamaño del patch debe ser mayor que 0.\"\n",
    "        assert patch_size * num_patches <= 150 * 150, \"Demasiados patches para esta resolución.\"\n",
    "        \n",
    "        # Calcular la cuadrícula de celdas no superpuestas\n",
    "        grid_rows = 150 // patch_size\n",
    "        grid_cols = 150 // patch_size\n",
    "        total_cells = grid_rows * grid_cols\n",
    "\n",
    "        assert num_patches <= total_cells, \"Demasiados patches para el tamaño del patch y la resolución de la imagen.\"\n",
    "        \n",
    "        # Generar las posiciones de la cuadrícula\n",
    "        all_positions = [(i * patch_size, j * patch_size) for i in range(grid_rows) for j in range(grid_cols)]\n",
    "\n",
    "        # Calcular las distancias de las celdas al centro de la imagen\n",
    "        center = (150 // 2, 150 // 2)\n",
    "        distances = [\n",
    "            np.sqrt((row + patch_size // 2 - center[0])**2 + (col + patch_size // 2 - center[1])**2)\n",
    "            for row, col in all_positions\n",
    "        ]\n",
    "\n",
    "        # Ordenar las posiciones por cercanía al centro\n",
    "        sorted_positions = [pos for _, pos in sorted(zip(distances, all_positions))]\n",
    "        \n",
    "        # Seleccionar los patches más céntricos\n",
    "        np.random.seed(seed)\n",
    "        selected_positions = sorted_positions[:num_patches]\n",
    "        \n",
    "        # Extraer los patches en las posiciones seleccionadas\n",
    "        patches = [img[row:row + patch_size, col:col + patch_size] for row, col in selected_positions]\n",
    "\n",
    "        #self.visualize_disjoint_patches(img, patches, selected_positions, patch_size)\n",
    "        \n",
    "        return np.array(patches)\n",
    "\n",
    "\n",
    "    def bovw(self, images, patchSize, nClusters, maxPatches):\n",
    "        bufferData = []\n",
    "        for i in images:\n",
    "            resized_img = cv2.resize(i, (150, 150), interpolation=cv2.INTER_AREA)\n",
    "            patches = self.extract_centric_patches(resized_img, patchSize, num_patches=maxPatches, seed=27) # shape = (maxPatches,5,5,3)\n",
    "            patches = np.reshape(patches, (len(patches), -1)) # shape = (maxPatches,75)\n",
    "            bufferData.append(patches)\n",
    "        dataIm = np.concatenate(bufferData, axis=0) # shape = (200*maxPatches,75)  n patches x 200 imágenes\n",
    "        dataIm = dataIm.astype(float)\n",
    "        dataIm -= np.mean(dataIm, axis=0)\n",
    "        dataIm /= np.std(dataIm, axis=0)\n",
    "        kmeans = MiniBatchKMeans(n_clusters=nClusters, random_state=27, verbose=False)\n",
    "        kmeans.partial_fit(dataIm)\n",
    "\n",
    "        X = np.reshape(kmeans.labels_ , (len(images),maxPatches)) # Indice de cluster de cada patch. shape = (200,maxPatches)\n",
    "        resul = [np.bincount(row, minlength=nClusters) for row in X]\n",
    "        resul = np.array(resul)\n",
    "        return resul\n",
    "\n",
    "    def transform(self, images):\n",
    "        # Aplica tu función de preprocesamiento aquí\n",
    "        # Por ejemplo:\n",
    "        # return your_custom_function(X, param1=self.param1)\n",
    "        return self.bovw(images, self.patchSize, self.nClusters, self.max_patches)  # Devuelve los datos preprocesados\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = LabelEncoder()\n",
    "X = bufferImages\n",
    "y_cod = enc.fit_transform(y)\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y_cod, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SVC()\n",
    "pca = PCA()\n",
    "proc = CustomBoVWPreprocessorSamePatches()\n",
    "\n",
    "pipe = Pipeline([('proc', proc), ('pca', pca), ('svm', svm)])\n",
    "G = {'svm__C': [0.1, 1], 'svm__kernel':['rbf'], 'svm__gamma': [0.1, 1], 'pca__n_components': [10]}\n",
    "gs = GridSearchCV(pipe, G, cv=4, refit=True, verbose=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 4 candidates, totalling 16 fits\n",
      "[CV 1/4; 1/4] START pca__n_components=10, svm__C=0.1, svm__gamma=0.1, svm__kernel=rbf\n",
      "[CV 1/4; 1/4] END pca__n_components=10, svm__C=0.1, svm__gamma=0.1, svm__kernel=rbf;, score=0.250 total time=   0.8s\n",
      "[CV 2/4; 1/4] START pca__n_components=10, svm__C=0.1, svm__gamma=0.1, svm__kernel=rbf\n",
      "[CV 2/4; 1/4] END pca__n_components=10, svm__C=0.1, svm__gamma=0.1, svm__kernel=rbf;, score=0.250 total time=   0.6s\n",
      "[CV 3/4; 1/4] START pca__n_components=10, svm__C=0.1, svm__gamma=0.1, svm__kernel=rbf\n",
      "[CV 3/4; 1/4] END pca__n_components=10, svm__C=0.1, svm__gamma=0.1, svm__kernel=rbf;, score=0.250 total time=   0.6s\n",
      "[CV 4/4; 1/4] START pca__n_components=10, svm__C=0.1, svm__gamma=0.1, svm__kernel=rbf\n",
      "[CV 4/4; 1/4] END pca__n_components=10, svm__C=0.1, svm__gamma=0.1, svm__kernel=rbf;, score=0.250 total time=   0.6s\n",
      "[CV 1/4; 2/4] START pca__n_components=10, svm__C=0.1, svm__gamma=1, svm__kernel=rbf\n",
      "[CV 1/4; 2/4] END pca__n_components=10, svm__C=0.1, svm__gamma=1, svm__kernel=rbf;, score=0.250 total time=   0.6s\n",
      "[CV 2/4; 2/4] START pca__n_components=10, svm__C=0.1, svm__gamma=1, svm__kernel=rbf\n",
      "[CV 2/4; 2/4] END pca__n_components=10, svm__C=0.1, svm__gamma=1, svm__kernel=rbf;, score=0.250 total time=   0.6s\n",
      "[CV 3/4; 2/4] START pca__n_components=10, svm__C=0.1, svm__gamma=1, svm__kernel=rbf\n",
      "[CV 3/4; 2/4] END pca__n_components=10, svm__C=0.1, svm__gamma=1, svm__kernel=rbf;, score=0.250 total time=   0.6s\n",
      "[CV 4/4; 2/4] START pca__n_components=10, svm__C=0.1, svm__gamma=1, svm__kernel=rbf\n",
      "[CV 4/4; 2/4] END pca__n_components=10, svm__C=0.1, svm__gamma=1, svm__kernel=rbf;, score=0.250 total time=   0.6s\n",
      "[CV 1/4; 3/4] START pca__n_components=10, svm__C=1, svm__gamma=0.1, svm__kernel=rbf\n",
      "[CV 1/4; 3/4] END pca__n_components=10, svm__C=1, svm__gamma=0.1, svm__kernel=rbf;, score=0.400 total time=   0.6s\n",
      "[CV 2/4; 3/4] START pca__n_components=10, svm__C=1, svm__gamma=0.1, svm__kernel=rbf\n",
      "[CV 2/4; 3/4] END pca__n_components=10, svm__C=1, svm__gamma=0.1, svm__kernel=rbf;, score=0.350 total time=   0.6s\n",
      "[CV 3/4; 3/4] START pca__n_components=10, svm__C=1, svm__gamma=0.1, svm__kernel=rbf\n",
      "[CV 3/4; 3/4] END pca__n_components=10, svm__C=1, svm__gamma=0.1, svm__kernel=rbf;, score=0.275 total time=   0.6s\n",
      "[CV 4/4; 3/4] START pca__n_components=10, svm__C=1, svm__gamma=0.1, svm__kernel=rbf\n",
      "[CV 4/4; 3/4] END pca__n_components=10, svm__C=1, svm__gamma=0.1, svm__kernel=rbf;, score=0.250 total time=   0.6s\n",
      "[CV 1/4; 4/4] START pca__n_components=10, svm__C=1, svm__gamma=1, svm__kernel=rbf\n",
      "[CV 1/4; 4/4] END pca__n_components=10, svm__C=1, svm__gamma=1, svm__kernel=rbf;, score=0.250 total time=   0.6s\n",
      "[CV 2/4; 4/4] START pca__n_components=10, svm__C=1, svm__gamma=1, svm__kernel=rbf\n",
      "[CV 2/4; 4/4] END pca__n_components=10, svm__C=1, svm__gamma=1, svm__kernel=rbf;, score=0.325 total time=   0.7s\n",
      "[CV 3/4; 4/4] START pca__n_components=10, svm__C=1, svm__gamma=1, svm__kernel=rbf\n",
      "[CV 3/4; 4/4] END pca__n_components=10, svm__C=1, svm__gamma=1, svm__kernel=rbf;, score=0.250 total time=   0.8s\n",
      "[CV 4/4; 4/4] START pca__n_components=10, svm__C=1, svm__gamma=1, svm__kernel=rbf\n",
      "[CV 4/4; 4/4] END pca__n_components=10, svm__C=1, svm__gamma=1, svm__kernel=rbf;, score=0.250 total time=   0.6s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-3 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-3 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-3 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-3 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-3 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-3 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=4,\n",
       "             estimator=Pipeline(steps=[(&#x27;proc&#x27;,\n",
       "                                        CustomBoVWPreprocessorSamePatches()),\n",
       "                                       (&#x27;pca&#x27;, PCA()), (&#x27;svm&#x27;, SVC())]),\n",
       "             param_grid={&#x27;pca__n_components&#x27;: [10], &#x27;svm__C&#x27;: [0.1, 1],\n",
       "                         &#x27;svm__gamma&#x27;: [0.1, 1], &#x27;svm__kernel&#x27;: [&#x27;rbf&#x27;]},\n",
       "             verbose=10)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;GridSearchCV<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.model_selection.GridSearchCV.html\">?<span>Documentation for GridSearchCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>GridSearchCV(cv=4,\n",
       "             estimator=Pipeline(steps=[(&#x27;proc&#x27;,\n",
       "                                        CustomBoVWPreprocessorSamePatches()),\n",
       "                                       (&#x27;pca&#x27;, PCA()), (&#x27;svm&#x27;, SVC())]),\n",
       "             param_grid={&#x27;pca__n_components&#x27;: [10], &#x27;svm__C&#x27;: [0.1, 1],\n",
       "                         &#x27;svm__gamma&#x27;: [0.1, 1], &#x27;svm__kernel&#x27;: [&#x27;rbf&#x27;]},\n",
       "             verbose=10)</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">best_estimator_: Pipeline</label><div class=\"sk-toggleable__content fitted\"><pre>Pipeline(steps=[(&#x27;proc&#x27;, CustomBoVWPreprocessorSamePatches()),\n",
       "                (&#x27;pca&#x27;, PCA(n_components=10)), (&#x27;svm&#x27;, SVC(C=1, gamma=0.1))])</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">CustomBoVWPreprocessorSamePatches</label><div class=\"sk-toggleable__content fitted\"><pre>CustomBoVWPreprocessorSamePatches()</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;PCA<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.decomposition.PCA.html\">?<span>Documentation for PCA</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>PCA(n_components=10)</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" ><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;SVC<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.svm.SVC.html\">?<span>Documentation for SVC</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>SVC(C=1, gamma=0.1)</pre></div> </div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=4,\n",
       "             estimator=Pipeline(steps=[('proc',\n",
       "                                        CustomBoVWPreprocessorSamePatches()),\n",
       "                                       ('pca', PCA()), ('svm', SVC())]),\n",
       "             param_grid={'pca__n_components': [10], 'svm__C': [0.1, 1],\n",
       "                         'svm__gamma': [0.1, 1], 'svm__kernel': ['rbf']},\n",
       "             verbose=10)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Los resultados en train son:\n",
      "   mean_test_score                                             params\n",
      "0          0.25000  {'pca__n_components': 10, 'svm__C': 0.1, 'svm_...\n",
      "1          0.25000  {'pca__n_components': 10, 'svm__C': 0.1, 'svm_...\n",
      "2          0.31875  {'pca__n_components': 10, 'svm__C': 1, 'svm__g...\n",
      "3          0.26875  {'pca__n_components': 10, 'svm__C': 1, 'svm__g...\n",
      "Los mejores parámetros son:\n",
      "{'pca__n_components': 10, 'svm__C': 1, 'svm__gamma': 0.1, 'svm__kernel': 'rbf'}\n",
      "Con score:\n",
      "0.31875\n",
      "Los resultados en test:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.82      0.40        11\n",
      "           1       1.00      0.11      0.20         9\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        10\n",
      "\n",
      "    accuracy                           0.25        40\n",
      "   macro avg       0.32      0.23      0.15        40\n",
      "weighted avg       0.30      0.25      0.15        40\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Los resultados en train son:')\n",
    "show_results_gs(gs)\n",
    "print('Los mejores parámetros son:')\n",
    "print(gs.best_params_)\n",
    "print('Con score:')\n",
    "print(gs.best_score_)\n",
    "print('Los resultados en test:')\n",
    "y_preds = gs.predict(x_test)\n",
    "print(classification_report(y_test, y_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Terriblemente mal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
