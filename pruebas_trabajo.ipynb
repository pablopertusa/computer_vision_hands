{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pruebas Trabajo con MLPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import SGD\n",
    "from tensorflow import keras\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from keras import Sequential\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from keras.layers import Dense, Input, Dropout, Flatten\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "Comprobación: True\n"
     ]
    }
   ],
   "source": [
    "dataset_path = '/home/pablo/Desktop/tercero/mdp/trabajo/HANDS'   # Cambiar por la carpeta en la que se encuentran las imágenes\n",
    " \n",
    "jpgFiles = [fJPG for fJPG in os.listdir(dataset_path) if fJPG.endswith('.jpg')]\n",
    "\n",
    "bufferImages = []\n",
    "y = []\n",
    "\n",
    "# Extraer 50 patches aleatorios de cada imagen\n",
    "for filename in jpgFiles:\n",
    "    img_path = os.path.join(dataset_path, filename)\n",
    "    label = filename.split('.')[0][-2:]\n",
    "    y.append(label)\n",
    "    with open(img_path) as infile:\n",
    "        # Obtener etiqueta\n",
    "        img_label = filename[5:7] \n",
    "        # Leer imagen\n",
    "        img = cv2.imread(img_path)\n",
    "        # Convertir imagen de BGR a RGB\n",
    "        img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        bufferImages.append(img_gray)\n",
    "print(len(bufferImages))\n",
    "print('Comprobación:', all([x in ['RB', 'RF', 'LB', 'LF'] for x in y]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomPreprocessorSamePatches(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, patchSize=10, nClusters = 81, max_patches=50):\n",
    "        self.patchSize = patchSize\n",
    "        self.nClusters = nClusters\n",
    "        self.max_patches = max_patches\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self       \n",
    "    \n",
    "    def extract_centric_patches(self, img, patch_size, num_patches, seed=42):\n",
    "        assert img.shape == (150, 150), \"La imagen debe tener resolución 150x150.\"\n",
    "        assert patch_size > 0, \"El tamaño del patch debe ser mayor que 0.\"\n",
    "        assert patch_size * num_patches <= 150 * 150, \"Demasiados patches para esta resolución.\"\n",
    "        \n",
    "        # Calcular la cuadrícula de celdas no superpuestas\n",
    "        grid_rows = 150 // patch_size\n",
    "        grid_cols = 150 // patch_size\n",
    "        total_cells = grid_rows * grid_cols\n",
    "\n",
    "        assert num_patches <= total_cells, \"Demasiados patches para el tamaño del patch y la resolución de la imagen.\"\n",
    "        \n",
    "        # Generar las posiciones de la cuadrícula\n",
    "        all_positions = [(i * patch_size, j * patch_size) for i in range(grid_rows) for j in range(grid_cols)]\n",
    "\n",
    "        # Calcular las distancias de las celdas al centro de la imagen\n",
    "        center = (150 // 2, 150 // 2)\n",
    "        distances = [\n",
    "            np.sqrt((row + patch_size // 2 - center[0])**2 + (col + patch_size // 2 - center[1])**2)\n",
    "            for row, col in all_positions\n",
    "        ]\n",
    "\n",
    "        # Ordenar las posiciones por cercanía al centro\n",
    "        sorted_positions = [pos for _, pos in sorted(zip(distances, all_positions))]\n",
    "        \n",
    "        # Seleccionar los patches más céntricos\n",
    "        np.random.seed(seed)\n",
    "        selected_positions = sorted_positions[:num_patches]\n",
    "        \n",
    "        # Extraer los patches en las posiciones seleccionadas\n",
    "        patches = [img[row:row + patch_size, col:col + patch_size] for row, col in selected_positions]\n",
    "\n",
    "        #self.visualize_disjoint_patches(img, patches, selected_positions, patch_size)\n",
    "        \n",
    "        return np.array(patches)\n",
    "\n",
    "\n",
    "    def bovw(self, images, patchSize, nClusters, maxPatches):\n",
    "        bufferData = []\n",
    "        for i in images:\n",
    "            resized_img = cv2.resize(i, (150, 150), interpolation=cv2.INTER_AREA)\n",
    "            patches = self.extract_centric_patches(resized_img, patchSize, num_patches=maxPatches, seed=27)\n",
    "            patches = np.reshape(patches, (len(patches), -1))\n",
    "            bufferData.append(patches)\n",
    "            \n",
    "        bufferData = np.array(bufferData)\n",
    "        print(bufferData.shape)\n",
    "        return bufferData\n",
    "\n",
    "    def transform(self, images):\n",
    "        # Aplica tu función de preprocesamiento aquí\n",
    "        # Por ejemplo:\n",
    "        # return your_custom_function(X, param1=self.param1)\n",
    "        return self.bovw(images, self.patchSize, self.nClusters, self.max_patches)  # Devuelve los datos preprocesados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 50, 100)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[135, 135, 130, ..., 131, 128, 120],\n",
       "        [128, 125, 116, ..., 125, 124, 122],\n",
       "        [114, 113, 118, ..., 105,  70,  54],\n",
       "        ...,\n",
       "        [129, 126, 123, ..., 126, 122, 119],\n",
       "        [178, 172, 180, ..., 187, 181, 164],\n",
       "        [140, 138, 137, ...,  97,  99, 100]],\n",
       "\n",
       "       [[134, 133, 132, ..., 128, 126, 125],\n",
       "        [134, 132, 134, ..., 130, 130, 130],\n",
       "        [114, 114, 119, ..., 127, 128, 129],\n",
       "        ...,\n",
       "        [162, 166, 169, ..., 170, 169, 168],\n",
       "        [ 90,  94,  98, ...,  92,  96, 104],\n",
       "        [161, 162, 162, ..., 127, 126, 125]],\n",
       "\n",
       "       [[123, 124, 126, ..., 132, 130, 128],\n",
       "        [121, 117, 121, ..., 124, 123, 122],\n",
       "        [127, 128, 129, ..., 122, 124, 127],\n",
       "        ...,\n",
       "        [140, 140, 144, ..., 137, 137, 137],\n",
       "        [149, 152, 153, ..., 147, 147, 147],\n",
       "        [ 58,  74,  88, ..., 111, 128, 131]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[162, 162, 167, ..., 201, 200, 201],\n",
       "        [199, 197, 185, ..., 189, 190, 190],\n",
       "        [160, 161, 161, ..., 196, 196, 196],\n",
       "        ...,\n",
       "        [188, 187, 188, ..., 194, 194, 196],\n",
       "        [116, 103,  70, ..., 151, 152, 152],\n",
       "        [110, 119, 118, ..., 102, 101,  98]],\n",
       "\n",
       "       [[158, 156, 152, ..., 151, 145, 144],\n",
       "        [145, 145, 148, ..., 112, 108, 168],\n",
       "        [160, 161, 150, ..., 162, 160, 156],\n",
       "        ...,\n",
       "        [182, 183, 184, ..., 131, 147, 163],\n",
       "        [137, 137, 140, ..., 137, 132, 127],\n",
       "        [197, 197, 197, ..., 147, 136, 146]],\n",
       "\n",
       "       [[123, 111,  88, ...,  73, 115, 148],\n",
       "        [ 86,  87,  88, ...,  88, 131, 140],\n",
       "        [196, 196, 154, ..., 137, 126, 117],\n",
       "        ...,\n",
       "        [130, 135, 119, ...,  78,  79,  78],\n",
       "        [103, 105, 107, ..., 100,  98,  96],\n",
       "        [199, 198, 198, ..., 194, 194, 193]]], dtype=uint8)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cp = CustomPreprocessorSamePatches()\n",
    "resul = cp.transform(bufferImages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Input(shape=(50, 100)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(4, activation='softmax'))\n",
    "model.compile(optimizer = SGD(), loss='categorical_crossentropy',\n",
    "                metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: 'RB'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m y_one_hot \u001b[38;5;241m=\u001b[39m \u001b[43mto_categorical\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m x_train, x_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(resul, y_one_hot, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m)\n\u001b[1;32m      4\u001b[0m history \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit(x_train, y_train, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m60\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/tercero/mdp/trabajo/venv/lib/python3.12/site-packages/keras/src/utils/numerical_utils.py:87\u001b[0m, in \u001b[0;36mto_categorical\u001b[0;34m(x, num_classes)\u001b[0m\n\u001b[1;32m     85\u001b[0m         x \u001b[38;5;241m=\u001b[39m backend\u001b[38;5;241m.\u001b[39mnumpy\u001b[38;5;241m.\u001b[39mreshape(x, newshape)\n\u001b[1;32m     86\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m backend\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mone_hot(x, num_classes)\n\u001b[0;32m---> 87\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mint64\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     88\u001b[0m input_shape \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m     90\u001b[0m \u001b[38;5;66;03m# Shrink the last dimension if the shape is (..., 1).\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 10: 'RB'"
     ]
    }
   ],
   "source": [
    "y_one_hot = to_categorical(y, 4)\n",
    "x_train, x_test, y_train, y_test = train_test_split(resul, y_one_hot, test_size=0.2)\n",
    "\n",
    "history = model.fit(x_train, y_train, epochs=60, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 50, 100)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
